{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Weather data assembly notebook\n",
    "    # I'll import all data, assemble it, and run some preliminary graphing to find out a little bit about it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import openpyxl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assemble the dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw-weather-data/3151369.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Let's get all of our files\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../data/raw-weather-data/3151369.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_weather_database.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_weather_database.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mH:\\github\\weld-county-weather-accidents\\venv310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mH:\\github\\weld-county-weather-accidents\\venv310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mH:\\github\\weld-county-weather-accidents\\venv310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\github\\weld-county-weather-accidents\\venv310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mH:\\github\\weld-county-weather-accidents\\venv310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\github\\weld-county-weather-accidents\\venv310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mH:\\github\\weld-county-weather-accidents\\venv310\\lib\\site-packages\\pandas\\io\\common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/raw-weather-data/3151369.csv'"
     ]
    }
   ],
   "source": [
    "# Let's get all of our files\n",
    "df = pd.read_csv('.../data/raw-weather-data/3151369.csv')\n",
    "df.to_csv('full_weather_database.csv', index=False)\n",
    "df = pd.read_csv('full_weather_database.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4687 entries, 0 to 4686\n",
      "Data columns (total 65 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   STATION          4687 non-null   object \n",
      " 1   NAME             4687 non-null   object \n",
      " 2   DATE             4687 non-null   object \n",
      " 3   AWND             4474 non-null   float64\n",
      " 4   AWND_ATTRIBUTES  4474 non-null   object \n",
      " 5   PRCP             4504 non-null   float64\n",
      " 6   PRCP_ATTRIBUTES  4504 non-null   object \n",
      " 7   PSUN             1004 non-null   float64\n",
      " 8   PSUN_ATTRIBUTES  1004 non-null   object \n",
      " 9   SNOW             4687 non-null   float64\n",
      " 10  SNOW_ATTRIBUTES  4687 non-null   object \n",
      " 11  SNWD             4687 non-null   float64\n",
      " 12  SNWD_ATTRIBUTES  4687 non-null   object \n",
      " 13  TAVG             2130 non-null   float64\n",
      " 14  TAVG_ATTRIBUTES  2130 non-null   object \n",
      " 15  TMAX             4474 non-null   float64\n",
      " 16  TMAX_ATTRIBUTES  4474 non-null   object \n",
      " 17  TMIN             4474 non-null   float64\n",
      " 18  TMIN_ATTRIBUTES  4474 non-null   object \n",
      " 19  TSUN             1004 non-null   float64\n",
      " 20  TSUN_ATTRIBUTES  1004 non-null   object \n",
      " 21  WESD             3 non-null      float64\n",
      " 22  WESD_ATTRIBUTES  3 non-null      object \n",
      " 23  WSF2             4474 non-null   float64\n",
      " 24  WSF2_ATTRIBUTES  4474 non-null   object \n",
      " 25  WSF5             4462 non-null   float64\n",
      " 26  WSF5_ATTRIBUTES  4462 non-null   object \n",
      " 27  WT01             1127 non-null   float64\n",
      " 28  WT01_ATTRIBUTES  1127 non-null   object \n",
      " 29  WT02             359 non-null    float64\n",
      " 30  WT02_ATTRIBUTES  359 non-null    object \n",
      " 31  WT03             650 non-null    float64\n",
      " 32  WT03_ATTRIBUTES  650 non-null    object \n",
      " 33  WT04             22 non-null     float64\n",
      " 34  WT04_ATTRIBUTES  22 non-null     object \n",
      " 35  WT05             208 non-null    float64\n",
      " 36  WT05_ATTRIBUTES  208 non-null    object \n",
      " 37  WT06             40 non-null     float64\n",
      " 38  WT06_ATTRIBUTES  40 non-null     object \n",
      " 39  WT07             75 non-null     float64\n",
      " 40  WT07_ATTRIBUTES  75 non-null     object \n",
      " 41  WT08             554 non-null    float64\n",
      " 42  WT08_ATTRIBUTES  554 non-null    object \n",
      " 43  WT09             92 non-null     float64\n",
      " 44  WT09_ATTRIBUTES  92 non-null     object \n",
      " 45  WT10             6 non-null      float64\n",
      " 46  WT10_ATTRIBUTES  6 non-null      object \n",
      " 47  WT11             44 non-null     float64\n",
      " 48  WT11_ATTRIBUTES  44 non-null     object \n",
      " 49  WT13             425 non-null    float64\n",
      " 50  WT13_ATTRIBUTES  425 non-null    object \n",
      " 51  WT14             36 non-null     float64\n",
      " 52  WT14_ATTRIBUTES  36 non-null     object \n",
      " 53  WT15             8 non-null      float64\n",
      " 54  WT15_ATTRIBUTES  8 non-null      object \n",
      " 55  WT16             566 non-null    float64\n",
      " 56  WT16_ATTRIBUTES  566 non-null    object \n",
      " 57  WT17             5 non-null      float64\n",
      " 58  WT17_ATTRIBUTES  5 non-null      object \n",
      " 59  WT18             320 non-null    float64\n",
      " 60  WT18_ATTRIBUTES  320 non-null    object \n",
      " 61  WT19             2 non-null      float64\n",
      " 62  WT19_ATTRIBUTES  2 non-null      object \n",
      " 63  WT22             127 non-null    float64\n",
      " 64  WT22_ATTRIBUTES  127 non-null    object \n",
      "dtypes: float64(31), object(34)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's make our data more readable, feature engineer, and trim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# We can get rid of the STATION feature since we know this set is from DIA. WESD is almost entirely null so let's get rid of it. There are some other categories that we just won't need because the data is either duplicated, or worthless for our use."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# So we need to clean missing values, and fix the temperatures which are missing for a decent portion of the dataset. I'll need to get another dataset to do that. Should I feature engineer the temperature variance for each day? That could be interesting. If there's a high variance maybe snow is more likely to melt?\n",
    "# We also need to rename some of these columns for clarity. Let's do that first. You could skip this step if you're happy with how they are."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def trim_and_rename(passed_df, column_list):\n",
    "    rename_dict = {\n",
    "                    'AWND': 'AVG_WIND_SPEED',\n",
    "                    'PRCP': 'PRECIPITATION',\n",
    "                    'SNOW': 'SNOWFALL',\n",
    "                    'SNWD': 'SNOW_DEPTH',\n",
    "                    'TAVG': 'AVG_TEMP',\n",
    "                    'WSF2': 'WIND_2MIN_FASTEST',\n",
    "                    'WSF5': 'WIND_5MIN_FASTEST',\n",
    "                    'WT01': 'WT_FOG',\n",
    "                    'WT02': 'WT_HEAVY_FOG',\n",
    "                    'WT03': 'WT_THUNDER',\n",
    "                    'WT04': 'WT_SMALL_HAIL',\n",
    "                    'WT05': 'WT_HAIL',\n",
    "                    'WT06': 'WT_FROST',\n",
    "                    'WT07': 'WT_BLOWING_DUST',\n",
    "                    'WT08': 'WT_SMOKE_OR_HAZE',\n",
    "                    'WT09': 'WT_DRIFTING_SNOW',\n",
    "                    'WT10': 'WT_TORNADO',\n",
    "                    'WT11': 'WT_HIGH_WINDS',\n",
    "                   # 'WT12': Doesn't exist in this dataset\n",
    "                    'WT13': 'WT_MIST',\n",
    "                    'WT14': 'WT_DRIZZLE',\n",
    "                    'WT15': 'WT_FREEZING_DRIZZLE',\n",
    "                    'WT16': 'WT_RAIN',\n",
    "                    'WT17': 'WT_FREEZING_RAIN',\n",
    "                    'WT18': 'WT_SNOW',\n",
    "                    'WT19': 'WT_UNK_PRECIPITATION',\n",
    "                   # 'WT20': Doesn't exist at all\n",
    "                   # 'WT21': Doesn't exist in this dataset\n",
    "                    'WT22': 'WT_FREEZING_FOG',\n",
    "                    'TMAX': 'TEMP_MAX',\n",
    "                    'TMIN': 'TEMP_MIN'\n",
    "                    }\n",
    "    passed_df['DATE'] = pd.to_datetime(passed_df['DATE'])\n",
    "    passed_df = passed_df[passed_df.columns.drop(list(passed_df.filter(regex='_ATTRIBUTES')))]\n",
    "    passed_df = passed_df.drop(column_list, axis=1)\n",
    "    passed_df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    return passed_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df = trim_and_rename(df, column_list=['STATION', 'WESD', 'NAME', 'PSUN', 'TSUN'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Let's see if we can add average temperature to the missing columns using temp max and mins\n",
    "def add_avg_temps(passed_df):\n",
    "    beginning_num = passed_df['AVG_TEMP'].isna().sum()\n",
    "    for row in passed_df.index:\n",
    "        if np.isnan(passed_df.at[row, 'AVG_TEMP']):\n",
    "            if not np.isnan(passed_df.at[row, 'TEMP_MAX']):\n",
    "                if not np.isnan(passed_df.at[row, 'TEMP_MIN']):\n",
    "                    min_temp = passed_df.at[row, 'TEMP_MIN']\n",
    "                    max_temp = passed_df.at[row, 'TEMP_MAX']\n",
    "                    passed_df.at[row, 'AVG_TEMP'] = (min_temp + max_temp) / 2\n",
    "    ending_num = passed_df['AVG_TEMP'].isna().sum()\n",
    "    total = str(beginning_num - ending_num)\n",
    "    print('Added ' + total + ' values to AVG_TEMP.')\n",
    "\n",
    "    return passed_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2344 values to AVG_TEMP.\n"
     ]
    }
   ],
   "source": [
    "df = add_avg_temps(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4687 entries, 0 to 4686\n",
      "Data columns (total 29 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   DATE                  4687 non-null   datetime64[ns]\n",
      " 1   AVG_WIND_SPEED        4474 non-null   float64       \n",
      " 2   PRECIPITATION         4504 non-null   float64       \n",
      " 3   SNOWFALL              4687 non-null   float64       \n",
      " 4   SNOW_DEPTH            4687 non-null   float64       \n",
      " 5   AVG_TEMP              4474 non-null   float64       \n",
      " 6   TEMP_MAX              4474 non-null   float64       \n",
      " 7   TEMP_MIN              4474 non-null   float64       \n",
      " 8   WIND_2MIN_FASTEST     4474 non-null   float64       \n",
      " 9   WIND_5MIN_FASTEST     4462 non-null   float64       \n",
      " 10  WT_FOG                1127 non-null   float64       \n",
      " 11  WT_HEAVY_FOG          359 non-null    float64       \n",
      " 12  WT_THUNDER            650 non-null    float64       \n",
      " 13  WT_SMALL_HAIL         22 non-null     float64       \n",
      " 14  WT_HAIL               208 non-null    float64       \n",
      " 15  WT_FROST              40 non-null     float64       \n",
      " 16  WT_BLOWING_DUST       75 non-null     float64       \n",
      " 17  WT_SMOKE_OR_HAZE      554 non-null    float64       \n",
      " 18  WT_DRIFTING_SNOW      92 non-null     float64       \n",
      " 19  WT_TORNADO            6 non-null      float64       \n",
      " 20  WT_HIGH_WINDS         44 non-null     float64       \n",
      " 21  WT_MIST               425 non-null    float64       \n",
      " 22  WT_DRIZZLE            36 non-null     float64       \n",
      " 23  WT_FREEZING_DRIZZLE   8 non-null      float64       \n",
      " 24  WT_RAIN               566 non-null    float64       \n",
      " 25  WT_FREEZING_RAIN      5 non-null      float64       \n",
      " 26  WT_SNOW               320 non-null    float64       \n",
      " 27  WT_UNK_PRECIPITATION  2 non-null      float64       \n",
      " 28  WT_FREEZING_FOG       127 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(28)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Let's see where the sets of NaN data are....\n",
    "#\n",
    " # for row in df.index:\n",
    " #    if np.isnan(df.at[row, 'AVG_TEMP']):\n",
    " #        print(row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Starts at row 2282, 2013-04-01 ends at 2494, 2013-11-30. Multiple features during this timeframe are missing values. We'll need to fill these. My first thought is to use another dataset from a close by station in order to replicate the original data. We're also coming back up here to add in the 2020 data at the same time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_additional = pd.read_csv('.../data/raw-weather-data/3160654.csv')\n",
    "df_additional2 = pd.read_csv('.../data/raw-weather-data/3161094.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# It looks like Central Park is the only set with a complete reading for the timeframe. That'll work."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df_additional = df_additional.loc[df_additional['NAME'] == 'DENVER CENTRAL PARK, CO US']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df_additional = trim_and_rename(df_additional, column_list=['STATION', 'WESD', 'NAME'])\n",
    "df_additional2 = trim_and_rename(df_additional2, column_list=['STATION', 'NAME'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 273 values to AVG_TEMP.\n",
      "Added 29 values to AVG_TEMP.\n"
     ]
    }
   ],
   "source": [
    "df_additional = add_avg_temps(df_additional)\n",
    "df_additional2 = add_avg_temps(df_additional2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def combine_df(big_df, little_df, third_df):\n",
    "    for row in big_df.index:\n",
    "        if np.isnan(big_df.at[row, 'TEMP_MAX']):\n",
    "            big_df.drop(index=row, inplace=True)\n",
    "\n",
    "    little_df['DATE'] = pd.to_datetime(little_df['DATE'])\n",
    "    big_df = pd.concat([big_df, little_df, third_df])\n",
    "    big_df.sort_values(by=['DATE'], axis=0, inplace=True)\n",
    "    big_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return big_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5114 entries, 0 to 5113\n",
      "Data columns (total 29 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   DATE                  5114 non-null   datetime64[ns]\n",
      " 1   AVG_WIND_SPEED        4840 non-null   float64       \n",
      " 2   PRECIPITATION         5114 non-null   float64       \n",
      " 3   SNOWFALL              5114 non-null   float64       \n",
      " 4   SNOW_DEPTH            5114 non-null   float64       \n",
      " 5   AVG_TEMP              5113 non-null   float64       \n",
      " 6   TEMP_MAX              5113 non-null   float64       \n",
      " 7   TEMP_MIN              5113 non-null   float64       \n",
      " 8   WIND_2MIN_FASTEST     4840 non-null   float64       \n",
      " 9   WIND_5MIN_FASTEST     4828 non-null   float64       \n",
      " 10  WT_FOG                1207 non-null   float64       \n",
      " 11  WT_HEAVY_FOG          379 non-null    float64       \n",
      " 12  WT_THUNDER            733 non-null    float64       \n",
      " 13  WT_SMALL_HAIL         22 non-null     float64       \n",
      " 14  WT_HAIL               212 non-null    float64       \n",
      " 15  WT_FROST              43 non-null     float64       \n",
      " 16  WT_BLOWING_DUST       79 non-null     float64       \n",
      " 17  WT_SMOKE_OR_HAZE      603 non-null    float64       \n",
      " 18  WT_DRIFTING_SNOW      93 non-null     float64       \n",
      " 19  WT_TORNADO            6 non-null      float64       \n",
      " 20  WT_HIGH_WINDS         44 non-null     float64       \n",
      " 21  WT_MIST               425 non-null    float64       \n",
      " 22  WT_DRIZZLE            36 non-null     float64       \n",
      " 23  WT_FREEZING_DRIZZLE   8 non-null      float64       \n",
      " 24  WT_RAIN               566 non-null    float64       \n",
      " 25  WT_FREEZING_RAIN      5 non-null      float64       \n",
      " 26  WT_SNOW               320 non-null    float64       \n",
      " 27  WT_UNK_PRECIPITATION  2 non-null      float64       \n",
      " 28  WT_FREEZING_FOG       127 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(28)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = combine_df(df, df_additional, df_additional2)\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Now lets take care of the rest of our NaN values.\n",
    "\n",
    "df.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df.to_csv('weather_cleaned.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# After looking at the crash data it looks like some of our dates are off. We can add all of 2020 weather data into the set. I'll go back up and import that."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
